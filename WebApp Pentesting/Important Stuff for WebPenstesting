Important Stuff for WebPenstesting:
==================================
Virtual Host:
	1 server, many sites
Status Codes:
	1xx => informational
	2xx => succesful request
	3xx => redirection
	4xx => request has error in it
	5xx => server encountered an issue fulfilling the request
	200 => ok
	301 => redirects the browser to a new url PERMANENTLY
	302 => redirects the browser to a new url TEMPORARILY
	304 => tells browser to use CACHED COPY of requested resource
	400 => invalid request
	401 => Authenciation required
	403 => not allowed to see the resource, even if authorized
	404 => requested resource does not exist
	500 => internal server error
HTTP verbs:
	Safe verbs:(read-only and dont alter the server)
		GET/HEAD/OPTIONS
	Unsafe verbs:(alters the server)
		POST/PUT/DELETE
	GET:
		x/login.php?id=1&pass=a
		no need to intercept
	HEAD:
		curl --head https://site.com
		Same as get except server response
	POST:
		x/login.php
		intercepted using burp
	PUT:
		it allows us to upload a file in some web directory:
		netcat:
			PUT /writable_folder/uploaded.html HTTP/1.1
			Host: domain.com
			Content-length: Content-length of file to upload
			<....content of file uploaded....>
	DELETE:
	CONNECT:
		tuneel within the HTTP protocol
	TRACE:
		echo the request as seen by the server
		Allows the client to see what is being recieved at other end of request chain.
		SHOULD NOT BE ENABLED in production
		finding TRACE enabled is a finding
		curl -i -H "cookie:---" X TRACE https://site.com
	PATCH:
	OPTIONS:
		helps in finding available verbs for a directory
		curl -i -X OPTIONS https://site.com
	How to find what verbs are supported?
		we can use "options", but it may be disabled by site.
		using the following bash script:(and netcat)
			#!/bin/bash
			for method in GET POST PUT TRACE CONNECT OPTIONS;
			do
				printf "$method / HTTP/1.1\r\nHost: www.site.com\r\n\r\n" | nc www.site.org 80
HTTP headers:
	Headers which start wiht "X-" are non-standard HTTP headers, which means that these headers are used by the webapp on its own, not by the HTTP protocol.
Session Tracking:
	Session:
		A session creates a file in a temporary directory on the server where registered session variables and their values are stored.
		This data will be available to all pages on the site during that visit.
		A session ends when:
			user closes the browser
			or after leaving the site, the server will terminate the session after a time period of commonly 30 mins
		Session Tokens:
			session_variable_nmae:value
			findig name of session variable:
				use google
				example => session-id, phpsessionid
			value of session token can be:
				base64 encoded
				hash => hashcat/JTR/crackstation/google
				unguessable
	Cookies:
		Cookies are text files stored on the client computer sent by Server and they are kept of use tracking purpose
		When next time browser sends any request to web server then it sends those cookies information to the server and server uses that information to identify the user.
		initial cookie header => set-cookie: <data>
		subsequent cookie header => cookie: <data>
		cookie flags:
			secure:
				HTTPS-only
				cookies are encrypted
			Http-only:
				JS cant access these cookies
Curl:
	curl -i -X POST http://ip:port --data "hello"
	options:
		--head => use head verb
		-X => specify request method(always specify method in caps)
		--data "value"=> used with -X post
		-H <header> => used to supply cookie for authenciated testing
		-i => show reponse headers
	difference between CURL and WGET:
		CURL => opens a webpage in a terminal.
Encodings:
	URL Encoding:
		Capatilization doesnt matter
		\n => %0A or %0a
		\r => %0D or %0d
		%20 => encoded space
		meyerweb.com/eric/tools/dencoder/ => site for URL encoding/decoding
	HTML Encoding:
		Symbols are encoded by html to maintain security
		Double Quotes => " => &quot; or &#34;
		Single Quotes => ' => &apos; or &#39;
		Less than => < => &lt; or &#60;
		Greater than => > => &gt; or &#62;
		Note:
			&#<ASCII value of symbol>;
	Double Encoding:
Security Mechanisms:
	Same Origin Policy:(SOP)
		It restricts how documents (D in DOM) can interact with resources loaded from another ORIGIN.
		Example: if a user visited malc.com and it invoked a GET request to site.com/profile, then, SOP would prevent malc.com from reading response of site.com/profile
		What is origin?
			Protocol (HTTP or HTTPS)
			host (www.site.com)
			port
			they determine the origin
Burp Suite:
	Basics:
		Target:
			sitemap:
				it has list of different websites we intercepted. Select the target_website and "add to scope"
				scope:
					where automated scanning and testing occurs
					non-scope items are not actively scanned
		Proxy:
			History:
				conatins all the last requests and their consecutive responses
		Change Request Method:
		Hot Keys:
			ctrl + shift + p => proxy
			ctrl + shift + r => Repeater
			ctrl + shift + I => intruder
			ctrl + r => send this to Repeater
			ctrl + i => send this to intruder
		change color in burp:
			user options -> display -> http message display
	Recon:
		spider:(step-1)
			it crawls the website and finds different files/forms/HTTP methods/ etc.
			Its the 1st step in a website pentest
			sitemap -> select website -> right click -> spider this host
		discover content:(step-2)
			there are some pages/folders which are not directly linked with website like /admin/
			sitemap -> select website-> right click -> egagement tools -> dicover content => this will open up the discovery module, then:
				click "session is not running": 
					it starts "smart bruteforcing":
						it means, burp learns from files and folders it find within the target and make better choices
		active scanner:(step-3)
			finds VULNERABILITIES by attacking parameters/requests
			sitemap -> select website -> right click -> actively scan this host
			NOTE:
				This is extremly loud on network. It may submit extensive queries in the application. So, its better to tell the client when we are gonna do this attack
			NOTE:
				To descrease scan times, increase the number of threads in "active can engine section"
				Be careful, as u may take down a small site, if thread count is too high
	Exploitation:
		Intruder:(automated FUZZING)
			types:	
				sniper => one payload at a time
				Battering RAM => gives same value to all payloads at same time
					USED FOR XSS
				Pitchfork => uses diff dictionary for all payloads 
				clusterbomb => same as pitchfork but every value in 1st dict is matched against every value of dict2
			FUZZING:
				parameter fuzzing:
					its different from directory bruteforcing as here we FUZZ parameters.
					items.php?id=x
					example:
						suppose a website is going to have a sale next week, its possible it has already uploaded the sale stuff, but made no links(due to which we are not able to see it), then we can use FUZZING to find sale items.
					Usage:
						XSS				
			Note:
				use seclists
		Repeater:
		sequencer:(for session token gathering)
			find a response having session tokens -> right click -> send to sequencer -> identify the session tokens to analyse -> click "Start live capture" (it will start generating session tokens)
			it tells entropy(randomness), character-level analysis, bit-level analysis
	Extender:(Bwapp store)
		install the following extensions:
			Request Highlighter
				highlights the requests
			Turbo Intruder
				faster than burp intruder
				payload place => '%s'
				start/stop turbo intruder => ctrl + enter
			logger++
				logs every reqyest and response and can filter them
			sqlipy:
				sqlmap with burp
				pg-117(thpv2)
	Reporting:
		Scanner tab -> right click on selected url -> report selected issue
Chrome DevTools:
	for a bug bounty hunter, only 4 are important:
		console:
			its used to log messages along with the name of JS file which caused the message
				its done by using these JS func's:
					console.log("message")
					console.warn("message")
					console.error("message")
				to open that JS file, double click on its name, we will go to SOURCES tab showing using the JS file along with a highlighted line which caused the log.
			used to write custom JS, can be used in XSS
				> alert()
		sources:
			shows assets/resources
			a site can have assets of other sites too such as google fonts.
			we mostly use this to view JS files.
				when we open a JS file in it, to make it look less congested, click "{}" button on bottom left (a.k.a prettyprint)
				we can also debug JS files:
					done to understand the code, a.k.a static analysis
					to add a breakpoint, click on line number of JS code and reload the site, the site will pause at that breakpoint.
				we mostly look for "API keys" in JS files
					tool: subdomainizer (see RECON)
		network:
			it shows network requests when we reload the webpage
			settings:
				enable "disable cache":
					to not get cached responses from server/browser
				disbale "show overview":
					no use
			when we double click any request, it shows us:
				header
				preview => show preview/code
				reponse => raw interpreation by server
				indicator => chain of requests
				timing
				cookies
			it also has filters:(imp)
				they help us filters requests by JS/XHR/etc.
				JS files:
					right click	on JS file -> open in sources -> see code
				XHR files:
					XML HTTP Requests
					AJAX
					fetching remote files with JS
					its used for API Calls (/api)
		application:
		elements tab:
			HTML DOM
			it also corrects any mistakes in HTML code
			differnce b/w elements tab and page source:
				page source => shows ACTUAL HTML code
				elements tab => shows CORRECTED HTML code